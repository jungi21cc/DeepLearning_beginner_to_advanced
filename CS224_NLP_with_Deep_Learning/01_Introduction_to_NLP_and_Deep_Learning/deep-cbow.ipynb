{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import dynet as dy\n",
    "import numpy as np\n",
    "\n",
    "# Functions to read in the corpus\n",
    "w2i = defaultdict(lambda: len(w2i))\n",
    "t2i = defaultdict(lambda: len(t2i))\n",
    "UNK = w2i[\"<unk>\"]\n",
    "def read_dataset(filename):\n",
    "    with open(filename, \"r\") as f:\n",
    "        for line in f:\n",
    "            tag, words = line.lower().strip().split(\" ||| \")\n",
    "            yield ([w2i[x] for x in words.split(\" \")], t2i[tag])\n",
    "\n",
    "# Read in the data\n",
    "train = list(read_dataset(\"../data/classes/train.txt\"))\n",
    "w2i = defaultdict(lambda: UNK, w2i)\n",
    "dev = list(read_dataset(\"../data/classes/test.txt\"))\n",
    "nwords = len(w2i)\n",
    "ntags = len(t2i)\n",
    "\n",
    "# Start DyNet and define trainer\n",
    "model = dy.Model()\n",
    "trainer = dy.AdamTrainer(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "EMB_SIZE = 64\n",
    "HID_SIZE = 64\n",
    "HID_LAY = 2\n",
    "W_emb = model.add_lookup_parameters((nwords, EMB_SIZE)) # Word embeddings\n",
    "W_h = [model.add_parameters((HID_SIZE, EMB_SIZE if lay == 0 else HID_SIZE)) for lay in range(HID_LAY)]\n",
    "b_h = [model.add_parameters((HID_SIZE)) for lay in range(HID_LAY)]\n",
    "W_sm = model.add_parameters((ntags, HID_SIZE))          # Softmax weights\n",
    "b_sm = model.add_parameters((ntags))                    # Softmax bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to calculate scores for one value\n",
    "def calc_scores(words):\n",
    "    dy.renew_cg()\n",
    "    h = dy.esum([dy.lookup(W_emb, x) for x in words])\n",
    "    for W_h_i, b_h_i in zip(W_h, b_h):\n",
    "        h = dy.tanh( dy.parameter(W_h_i) * h + dy.parameter(b_h_i) )\n",
    "    return dy.parameter(W_sm) * h + dy.parameter(b_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0: train loss/sent=1.5361, time=1.19s\n",
      "iter 0: test acc=0.3891\n",
      "iter 1: train loss/sent=1.2601, time=1.17s\n",
      "iter 1: test acc=0.3928\n",
      "iter 2: train loss/sent=1.0434, time=1.20s\n",
      "iter 2: test acc=0.4059\n",
      "iter 3: train loss/sent=0.8101, time=1.18s\n",
      "iter 3: test acc=0.3964\n",
      "iter 4: train loss/sent=0.6126, time=1.42s\n",
      "iter 4: test acc=0.3828\n",
      "iter 5: train loss/sent=0.4459, time=1.52s\n",
      "iter 5: test acc=0.3878\n",
      "iter 6: train loss/sent=0.3142, time=1.39s\n",
      "iter 6: test acc=0.3674\n",
      "iter 7: train loss/sent=0.2288, time=1.35s\n",
      "iter 7: test acc=0.3783\n",
      "iter 8: train loss/sent=0.1603, time=1.38s\n",
      "iter 8: test acc=0.3742\n",
      "iter 9: train loss/sent=0.1205, time=1.86s\n",
      "iter 9: test acc=0.3715\n",
      "iter 10: train loss/sent=0.0811, time=1.37s\n",
      "iter 10: test acc=0.3738\n",
      "iter 11: train loss/sent=0.0548, time=1.22s\n",
      "iter 11: test acc=0.3548\n",
      "iter 12: train loss/sent=0.0464, time=1.51s\n",
      "iter 12: test acc=0.3683\n",
      "iter 13: train loss/sent=0.0350, time=1.54s\n",
      "iter 13: test acc=0.3692\n",
      "iter 14: train loss/sent=0.0332, time=1.68s\n",
      "iter 14: test acc=0.3733\n",
      "iter 15: train loss/sent=0.0271, time=1.38s\n",
      "iter 15: test acc=0.3561\n",
      "iter 16: train loss/sent=0.0266, time=1.49s\n",
      "iter 16: test acc=0.3566\n",
      "iter 17: train loss/sent=0.0195, time=1.38s\n",
      "iter 17: test acc=0.3774\n",
      "iter 18: train loss/sent=0.0280, time=1.27s\n",
      "iter 18: test acc=0.3769\n",
      "iter 19: train loss/sent=0.0254, time=1.31s\n",
      "iter 19: test acc=0.3710\n",
      "iter 20: train loss/sent=0.0259, time=1.24s\n",
      "iter 20: test acc=0.3742\n",
      "iter 21: train loss/sent=0.0287, time=1.25s\n",
      "iter 21: test acc=0.3647\n",
      "iter 22: train loss/sent=0.0195, time=1.26s\n",
      "iter 22: test acc=0.3792\n",
      "iter 23: train loss/sent=0.0344, time=1.23s\n",
      "iter 23: test acc=0.3719\n",
      "iter 24: train loss/sent=0.0259, time=1.21s\n",
      "iter 24: test acc=0.3670\n",
      "iter 25: train loss/sent=0.0330, time=1.52s\n",
      "iter 25: test acc=0.3787\n",
      "iter 26: train loss/sent=0.0315, time=1.35s\n",
      "iter 26: test acc=0.3656\n",
      "iter 27: train loss/sent=0.0257, time=1.28s\n",
      "iter 27: test acc=0.3796\n",
      "iter 28: train loss/sent=0.0188, time=1.21s\n",
      "iter 28: test acc=0.3769\n",
      "iter 29: train loss/sent=0.0275, time=1.36s\n",
      "iter 29: test acc=0.3742\n",
      "iter 30: train loss/sent=0.0204, time=1.33s\n",
      "iter 30: test acc=0.3602\n",
      "iter 31: train loss/sent=0.0222, time=1.35s\n",
      "iter 31: test acc=0.3719\n",
      "iter 32: train loss/sent=0.0253, time=1.36s\n",
      "iter 32: test acc=0.3715\n",
      "iter 33: train loss/sent=0.0179, time=1.25s\n",
      "iter 33: test acc=0.3769\n",
      "iter 34: train loss/sent=0.0291, time=1.08s\n",
      "iter 34: test acc=0.3751\n",
      "iter 35: train loss/sent=0.0314, time=0.89s\n",
      "iter 35: test acc=0.3742\n",
      "iter 36: train loss/sent=0.0244, time=0.91s\n",
      "iter 36: test acc=0.3751\n",
      "iter 37: train loss/sent=0.0284, time=0.94s\n",
      "iter 37: test acc=0.3760\n",
      "iter 38: train loss/sent=0.0223, time=0.91s\n",
      "iter 38: test acc=0.3760\n",
      "iter 39: train loss/sent=0.0335, time=0.97s\n",
      "iter 39: test acc=0.3679\n",
      "iter 40: train loss/sent=0.0255, time=0.91s\n",
      "iter 40: test acc=0.3597\n",
      "iter 41: train loss/sent=0.0207, time=0.94s\n",
      "iter 41: test acc=0.3715\n",
      "iter 42: train loss/sent=0.0216, time=0.97s\n",
      "iter 42: test acc=0.3719\n",
      "iter 43: train loss/sent=0.0272, time=1.07s\n",
      "iter 43: test acc=0.3701\n",
      "iter 44: train loss/sent=0.0292, time=1.02s\n",
      "iter 44: test acc=0.3548\n",
      "iter 45: train loss/sent=0.0191, time=0.94s\n",
      "iter 45: test acc=0.3557\n",
      "iter 46: train loss/sent=0.0315, time=1.14s\n",
      "iter 46: test acc=0.3701\n",
      "iter 47: train loss/sent=0.0151, time=0.98s\n",
      "iter 47: test acc=0.3638\n",
      "iter 48: train loss/sent=0.0209, time=0.89s\n",
      "iter 48: test acc=0.3710\n",
      "iter 49: train loss/sent=0.0187, time=0.91s\n",
      "iter 49: test acc=0.3710\n",
      "iter 50: train loss/sent=0.0214, time=0.89s\n",
      "iter 50: test acc=0.3656\n",
      "iter 51: train loss/sent=0.0189, time=0.90s\n",
      "iter 51: test acc=0.3738\n",
      "iter 52: train loss/sent=0.0174, time=0.91s\n",
      "iter 52: test acc=0.3656\n",
      "iter 53: train loss/sent=0.0280, time=1.21s\n",
      "iter 53: test acc=0.3747\n",
      "iter 54: train loss/sent=0.0189, time=1.24s\n",
      "iter 54: test acc=0.3715\n",
      "iter 55: train loss/sent=0.0318, time=1.17s\n",
      "iter 55: test acc=0.3774\n",
      "iter 56: train loss/sent=0.0201, time=0.94s\n",
      "iter 56: test acc=0.3787\n",
      "iter 57: train loss/sent=0.0211, time=0.92s\n",
      "iter 57: test acc=0.3701\n",
      "iter 58: train loss/sent=0.0304, time=0.98s\n",
      "iter 58: test acc=0.3652\n",
      "iter 59: train loss/sent=0.0126, time=1.00s\n",
      "iter 59: test acc=0.3719\n",
      "iter 60: train loss/sent=0.0211, time=0.91s\n",
      "iter 60: test acc=0.3633\n",
      "iter 61: train loss/sent=0.0287, time=1.00s\n",
      "iter 61: test acc=0.3715\n",
      "iter 62: train loss/sent=0.0269, time=0.92s\n",
      "iter 62: test acc=0.3661\n",
      "iter 63: train loss/sent=0.0196, time=0.97s\n",
      "iter 63: test acc=0.3805\n",
      "iter 64: train loss/sent=0.0203, time=0.93s\n",
      "iter 64: test acc=0.3670\n",
      "iter 65: train loss/sent=0.0287, time=0.97s\n",
      "iter 65: test acc=0.3774\n",
      "iter 66: train loss/sent=0.0193, time=0.99s\n",
      "iter 66: test acc=0.3769\n",
      "iter 67: train loss/sent=0.0282, time=0.95s\n",
      "iter 67: test acc=0.3738\n",
      "iter 68: train loss/sent=0.0359, time=0.99s\n",
      "iter 68: test acc=0.3787\n",
      "iter 69: train loss/sent=0.0202, time=1.04s\n",
      "iter 69: test acc=0.3674\n",
      "iter 70: train loss/sent=0.0290, time=0.96s\n",
      "iter 70: test acc=0.3611\n",
      "iter 71: train loss/sent=0.0161, time=0.90s\n",
      "iter 71: test acc=0.3828\n",
      "iter 72: train loss/sent=0.0192, time=1.03s\n",
      "iter 72: test acc=0.3674\n",
      "iter 73: train loss/sent=0.0175, time=0.96s\n",
      "iter 73: test acc=0.3606\n",
      "iter 74: train loss/sent=0.0170, time=0.98s\n",
      "iter 74: test acc=0.3615\n",
      "iter 75: train loss/sent=0.0299, time=1.00s\n",
      "iter 75: test acc=0.3833\n",
      "iter 76: train loss/sent=0.0240, time=1.09s\n",
      "iter 76: test acc=0.3796\n",
      "iter 77: train loss/sent=0.0293, time=0.95s\n",
      "iter 77: test acc=0.3796\n",
      "iter 78: train loss/sent=0.0222, time=0.95s\n",
      "iter 78: test acc=0.3706\n",
      "iter 79: train loss/sent=0.0322, time=1.02s\n",
      "iter 79: test acc=0.3756\n",
      "iter 80: train loss/sent=0.0153, time=0.98s\n",
      "iter 80: test acc=0.3765\n",
      "iter 81: train loss/sent=0.0296, time=1.04s\n",
      "iter 81: test acc=0.3633\n",
      "iter 82: train loss/sent=0.0200, time=0.98s\n",
      "iter 82: test acc=0.3652\n",
      "iter 83: train loss/sent=0.0155, time=0.92s\n",
      "iter 83: test acc=0.3706\n",
      "iter 84: train loss/sent=0.0269, time=0.94s\n",
      "iter 84: test acc=0.3643\n",
      "iter 85: train loss/sent=0.0250, time=0.99s\n",
      "iter 85: test acc=0.3751\n",
      "iter 86: train loss/sent=0.0189, time=0.97s\n",
      "iter 86: test acc=0.3710\n",
      "iter 87: train loss/sent=0.0228, time=0.91s\n",
      "iter 87: test acc=0.3724\n",
      "iter 88: train loss/sent=0.0376, time=1.14s\n",
      "iter 88: test acc=0.3760\n",
      "iter 89: train loss/sent=0.0223, time=1.08s\n",
      "iter 89: test acc=0.3606\n",
      "iter 90: train loss/sent=0.0287, time=0.94s\n",
      "iter 90: test acc=0.3674\n",
      "iter 91: train loss/sent=0.0171, time=1.02s\n",
      "iter 91: test acc=0.3783\n",
      "iter 92: train loss/sent=0.0273, time=1.03s\n",
      "iter 92: test acc=0.3670\n",
      "iter 93: train loss/sent=0.0195, time=1.03s\n",
      "iter 93: test acc=0.3643\n",
      "iter 94: train loss/sent=0.0200, time=1.10s\n",
      "iter 94: test acc=0.3584\n",
      "iter 95: train loss/sent=0.0328, time=1.18s\n",
      "iter 95: test acc=0.3498\n",
      "iter 96: train loss/sent=0.0276, time=1.28s\n",
      "iter 96: test acc=0.3697\n",
      "iter 97: train loss/sent=0.0239, time=1.00s\n",
      "iter 97: test acc=0.3715\n",
      "iter 98: train loss/sent=0.0316, time=0.99s\n",
      "iter 98: test acc=0.3697\n",
      "iter 99: train loss/sent=0.0295, time=0.98s\n",
      "iter 99: test acc=0.3652\n"
     ]
    }
   ],
   "source": [
    "for ITER in range(100):\n",
    "    # Perform training\n",
    "    random.shuffle(train)\n",
    "    train_loss = 0.0\n",
    "    start = time.time()\n",
    "    for words, tag in train:\n",
    "        my_loss = dy.pickneglogsoftmax(calc_scores(words), tag)\n",
    "        train_loss += my_loss.value()\n",
    "        my_loss.backward()\n",
    "        trainer.update()\n",
    "    print(\"iter %r: train loss/sent=%.4f, time=%.2fs\" % (ITER, train_loss/len(train), time.time()-start))\n",
    "    # Perform testing\n",
    "    test_correct = 0.0\n",
    "    for words, tag in dev:\n",
    "        scores = calc_scores(words).npvalue()\n",
    "        predict = np.argmax(scores)\n",
    "        if predict == tag:\n",
    "            test_correct += 1\n",
    "    print(\"iter %r: test acc=%.4f\" % (ITER, test_correct/len(dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
